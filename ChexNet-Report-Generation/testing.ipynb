{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid                                                         1\n",
      "findings    The cardiac silhouette and mediastinum size ar...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# print(data.columns)\n",
    "# Extract 'problems' and 'findings' columns\n",
    "df= pd.read_csv(\"C:\\FYP DATASET\\indiana_reports.csv\")[[\"uid\",\"findings\"]]\n",
    "#print df train element by element\n",
    "print(df.iloc[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)\n",
    "#Also print gpu name\n",
    "if device == 'cuda':\n",
    "    print(cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20% of the data randomly without replacement\n",
    "sample_df = df.sample(frac=0.2, random_state=42)  # random_state ensures reproducibility\n",
    "\n",
    "# If you need to reset the index of the sampled DataFrame\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1_IM-0001-4001.dcm.png', 'The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.'), ('1_IM-0001-3001.dcm.png', 'The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.'), ('2_IM-0652-1001.dcm.png', 'Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.'), ('2_IM-0652-2001.dcm.png', 'Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.'), ('3_IM-1384-1001.dcm.png', nan), ('3_IM-1384-2001.dcm.png', nan), ('4_IM-2050-1001.dcm.png', 'There are diffuse bilateral interstitial and alveolar opacities consistent with chronic obstructive lung disease and bullous emphysema. There are irregular opacities in the left lung apex, that could represent a cavitary lesion in the left lung apex.There are streaky opacities in the right upper lobe, XXXX scarring. The cardiomediastinal silhouette is normal in size and contour. There is no pneumothorax or large pleural effusion.'), ('4_IM-2050-2001.dcm.png', 'There are diffuse bilateral interstitial and alveolar opacities consistent with chronic obstructive lung disease and bullous emphysema. There are irregular opacities in the left lung apex, that could represent a cavitary lesion in the left lung apex.There are streaky opacities in the right upper lobe, XXXX scarring. The cardiomediastinal silhouette is normal in size and contour. There is no pneumothorax or large pleural effusion.'), ('5_IM-2117-1003002.dcm.png', 'The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There is no pneumothorax or pleural effusion. There are no focal areas of consolidation. Cholecystectomy clips are present. Small T-spine osteophytes. There is biapical pleural thickening, unchanged from prior. Mildly hyperexpanded lungs.'), ('5_IM-2117-1004003.dcm.png', 'The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There is no pneumothorax or pleural effusion. There are no focal areas of consolidation. Cholecystectomy clips are present. Small T-spine osteophytes. There is biapical pleural thickening, unchanged from prior. Mildly hyperexpanded lungs.')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sampled DataFrame (assuming you have already done this)\n",
    "sample_df = pd.read_csv(\"C:/FYP DATASET/indiana_reports.csv\")\n",
    "\n",
    "# Load the projections data\n",
    "projections_df = pd.read_csv(\"C:/FYP DATASET/indiana_projections.csv\")\n",
    "\n",
    "# Initialize an empty list to store (filename, finding) tuples\n",
    "filename_finding_pairs = []\n",
    "\n",
    "# Iterate over each row in your sampled DataFrame\n",
    "for index, row in sample_df.iterrows():\n",
    "    uid = row['uid']\n",
    "    finding = row['findings']\n",
    "    \n",
    "    # Find rows in projections_df where 'uid' matches\n",
    "    matched_filenames = projections_df[projections_df['uid'] == uid]['filename'].tolist()\n",
    "    \n",
    "    # For each filename matched, create a (filename, finding) tuple and append to the list\n",
    "    for filename in matched_filenames:\n",
    "        filename_finding_pairs.append((filename, finding))\n",
    "\n",
    "# Print the first few pairs to verify\n",
    "print(filename_finding_pairs[:10])  # Adjust as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1\n",
      "The chest X-ray shows no acute disease.\n",
      "\\images\\images_normalized\\image1\n",
      "Image 3999 not found.\n",
      "image2\n",
      "There is evidence of a consolidation in the right lower lobe suggesting pneumonia.\n",
      "\\images\\images_normalized\\image2\n",
      "Image 3999 not found.\n",
      "Average BLEU Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saad Subhani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Saad Subhani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import create_model as cm  # Ensure this is your module for loading models and such\n",
    "\n",
    "def load_model():\n",
    "    model_directory = \"/FYP_DATASET/results/\"\n",
    "    loaded_model = AutoModelForCausalLM.from_pretrained(model_directory)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    loaded_model = loaded_model.to(device)\n",
    "    return loaded_model, tokenizer, device\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # Perform any required preprocessing here\n",
    "    return np.array(image)\n",
    "\n",
    "def predict(image_1, image_2, model, tokenizer, device):\n",
    "    # Assuming `cm.function1` is your method to get captions from images, adjust as needed.\n",
    "    caption = cm.function1([image_1], [image_2 if image_2 is not None else image_1], model)\n",
    "\n",
    "    input_ids = tokenizer.encode(caption[0], return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200, pad_token_id=tokenizer.eos_token_id, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, repetition_penalty=1.0)\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return decoded_output\n",
    "\n",
    "def calculate_bleu_score(reference_text, candidate_text):\n",
    "    reference = [reference_text.split()]\n",
    "    candidate = candidate_text.split()\n",
    "    score = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))  # You can adjust weights\n",
    "    return score\n",
    "\n",
    "def evaluate_bleu_scores(filename_finding_pairs, image_directory):\n",
    "    model, tokenizer, device = load_model()\n",
    "    scores = []\n",
    "    \n",
    "    for image_name, actual_report in filename_finding_pairs:\n",
    "        print(image_name)\n",
    "        print(actual_report)\n",
    "        image_path = os.path.join(image_directory,image_name)  # Adjust format as needed\n",
    "        if not os.path.exists(image_path):\n",
    "            print(image_path)\n",
    "            print(f\"Image {uid} not found.\")\n",
    "            continue\n",
    "        \n",
    "        image_1 = preprocess_image(image_path)\n",
    "        generated_report = predict(image_1, None, model, tokenizer, device)\n",
    "        bleu_score = calculate_bleu_score(actual_report, generated_report)\n",
    "        scores.append(bleu_score)\n",
    "        print(f\"BLEU score for {uid}: {bleu_score}\")\n",
    "\n",
    "    average_bleu_score = np.mean(scores)\n",
    "    print(f\"Average BLEU Score: {average_bleu_score}\")\n",
    "\n",
    "# Example usage\n",
    "# filename_finding_pairs = [\n",
    "#     (\"image1\", \"The chest X-ray shows no acute disease.\"),\n",
    "#     (\"image2\", \"There is evidence of a consolidation in the right lower lobe suggesting pneumonia.\")\n",
    "# ]\n",
    "image_directory = \"\\images\\images_normalized\"  # Update this to your images' directory\n",
    "\n",
    "evaluate_bleu_scores(filename_finding_pairs, image_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Findings for UID 10: The cardiomediastinal silhouette is within normal limits for size and contour. The lungs are normally inflated without evidence of focal airspace disease, pleural effusion, or pneumothorax. Stable calcified granuloma within the right upper lung. No acute bone abnormality..\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_report_by_uid(uid, csv_file_path='indiana_reports.csv'):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Convert uid to int to match the DataFrame's format if necessary\n",
    "    uid_int = int(uid)\n",
    "    \n",
    "    # Find the row with the matching uid\n",
    "    report_row = df[df['uid'] == uid_int]\n",
    "    \n",
    "    # If a matching report is found, extract the findings\n",
    "    if not report_row.empty:\n",
    "        findings = report_row.iloc[0]['findings']\n",
    "        print(f\"Findings for UID {uid}: {findings}\")\n",
    "        return findings\n",
    "    else:\n",
    "        print(f\"No findings found for UID {uid}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "uid = 10  # Example UID extracted earlier\n",
    "csv_file_path = \"../indiana_reports.csv\"  # Adjust this path as necessary\n",
    "findings = get_report_by_uid(uid, csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
